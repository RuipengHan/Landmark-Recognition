{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36854,"status":"ok","timestamp":1712971168460,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"jookgGH2F3YB","outputId":"7b2e8e4d-8479-412d-b263-5cbdcbec0254"},"outputs":[],"source":["# !pip install torch\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1712970811353,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"LXbSZh7mBDgX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9951,"status":"ok","timestamp":1712971183014,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"GrVvBkSCd0-D"},"outputs":[],"source":["from torchvision import datasets, models, transforms\n","import os\n","import pandas as pd\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","class LandmarkImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, filenames_dir, transform=None, file_extension='.jpg'):\n","        \"\"\"\n","        Args:\n","            annotations_file (string): Path to the CSV file with annotations.\n","            img_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied on a sample.\n","            file_extension (string, optional): Extension of the image files in the directory.\n","        \"\"\"\n","        self.img_labels = pd.read_csv(annotations_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.file_extension = file_extension\n","        # Create a dictionary to map image IDs to labels\n","        self.id_to_label = {str(row[0]): row[3] for row in self.img_labels.values}\n","        # List all files in the img_dir\n","        # self.image_files = [f for f in os.listdir(img_dir) if f.endswith(file_extension)]\n","        df = pd.read_csv(filenames_dir)\n","        self.image_files = df['id'].tolist()\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_file = self.image_files[idx]\n","        img_id = os.path.splitext(img_file)[0]  # Remove extension to get the ID\n","        label = self.id_to_label[img_id]\n","        # print(f\"label: {label}\")\n","        img_path = os.path.join(self.img_dir, img_file)\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","# Define transformations for the training data\n","train_transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.RandomCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","label_csv = \"/content/drive/MyDrive/cs444-final-project/project/data/train/selected_train.csv\"\n","training_dir = \"/content/drive/MyDrive/cs444-final-project/project/data/selected_train\"\n","filenames = \"/content/drive/MyDrive/cs444-final-project/project/data/train_file_names.csv\"\n","# Create an instance of the dataset\n","train_dataset = LandmarkImageDataset(\n","    annotations_file=label_csv,\n","    img_dir=training_dir,\n","    filenames_dir=filenames,\n","    transform=train_transform,\n","    file_extension='.jpg'\n",")\n","\n","# Define the DataLoader\n","train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True, num_workers=2)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1712971193266,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"kH7nBdfYd0-E","outputId":"db2f42d3-6706-4614-a01f-0c852451a46e"},"outputs":[],"source":["# # Load a pretrained ResNet-50 model\n","# model = models.resnet50(pretrained=True)\n","\n","# # Modify the final layer for the number of classes we have\n","# num_classes = len(train_dataset.classes)\n","# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n","\n","from torchvision import models\n","import torch\n","\n","def initialize_model(num_classes):\n","    # Load a pretrained ResNet-18 model\n","    model = models.resnet18(pretrained=True)\n","    # Modify the final layer to match the number of classes\n","    num_ftrs = model.fc.in_features\n","    model.fc = torch.nn.Linear(num_ftrs, num_classes)\n","    return model\n","\n","# Determine the number of unique classes\n","# num_classes = len(set(train_dataset.id_to_label.values()))\n","num_classes = len(set(train_dataset.id_to_label.values()))\n","\n","# num_classes=2000\n","print(f\"number of classes {num_classes}\")\n","model = initialize_model(num_classes=num_classes)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":959,"status":"ok","timestamp":1712971197934,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"58TmUA2Cez8b"},"outputs":[],"source":["# def train_model(model, dataloader, loss_fn, optimizer, device, epochs=10):\n","#     model.to(device)\n","#     for epoch in tqdm.tqdm(range(epochs)):\n","#         model.train()\n","#         running_loss = 0.0\n","#         correct_predictions = 0\n","#         for inputs, labels in dataloader:\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","\n","#             optimizer.zero_grad()\n","#             outputs = model(inputs)\n","#             loss = loss_fn(outputs, labels)\n","#             loss.backward()\n","#             optimizer.step()\n","\n","#             running_loss += loss.item()\n","#             _, preds = torch.max(outputs, 1)\n","#             correct_predictions += torch.sum(preds == labels.data)\n","\n","#         epoch_loss = running_loss / len(dataloader)\n","#         epoch_acc = correct_predictions.double() / len(dataloader.dataset)\n","#         print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}, Accuracy: {epoch_acc}')\n","\n","# def evaluate_model(model, dataloader, loss_fn, device):\n","#     model.eval()\n","#     running_loss = 0.0\n","#     correct_predictions = 0\n","#     with torch.no_grad():\n","#         for inputs, labels in dataloader:\n","#             inputs, labels = inputs.to(device), labels.to(device)\n","#             outputs = model(inputs)\n","#             loss = loss_fn(outputs, labels)\n","\n","#             running_loss += loss.item()\n","#             _, preds = torch.max(outputs, 1)\n","#             correct_predictions += torch.sum(preds == labels.data)\n","\n","#     total_loss = running_loss / len(dataloader)\n","#     accuracy = correct_predictions.double() / len(dataloader.dataset)\n","#     print(f'Validation Loss: {total_loss}, Accuracy: {accuracy}')\n","\n","from tqdm import tqdm\n","\n","def train_model(model, dataloader, loss_fn, optimizer, device, epochs=10):\n","    model.to(device)\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        correct_predictions = 0\n","        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{epochs}\")\n","        for i, (inputs, labels) in progress_bar:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, preds = torch.max(outputs, 1)\n","            correct_predictions += torch.sum(preds == labels.data)\n","\n","            progress_bar.set_postfix({'loss': loss.item(), 'acc': torch.sum(preds == labels.data).item() / len(labels)})\n","\n","        epoch_loss = running_loss / len(dataloader)\n","        epoch_acc = correct_predictions.double() / len(dataloader.dataset)\n","        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}, Accuracy: {epoch_acc}')\n","\n","def evaluate_model(model, dataloader, loss_fn, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct_predictions = 0\n","    with torch.no_grad():\n","        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Evaluating\")\n","        for i, (inputs, labels) in progress_bar:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels)\n","\n","            running_loss += loss.item()\n","            _, preds = torch.max(outputs, 1)\n","            correct_predictions += torch.sum(preds == labels.data)\n","\n","            progress_bar.set_postfix({'loss': loss.item(), 'acc': torch.sum(preds == labels.data).item() / len(labels)})\n","\n","    total_loss = running_loss / len(dataloader)\n","    accuracy = correct_predictions.double() / len(dataloader.dataset)\n","    print(f'Validation Loss: {total_loss}, Accuracy: {accuracy}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712971232055,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"YNxedeone0i1","outputId":"cbaf0989-5e5e-4100-b97e-995557a02bd4"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","if torch.cuda.is_available():\n","  print(\"CUDA USED\")\n","else:\n","  print(\"CPU USED\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":724},"executionInfo":{"elapsed":120056,"status":"error","timestamp":1712971356050,"user":{"displayName":"Ruipeng Han","userId":"01141656125453541823"},"user_tz":420},"id":"d1cW55K7kO_M","outputId":"05a40bbb-84cb-4e5d-f13c-2ea2bfd6b6c7"},"outputs":[],"source":["# Initialize the model, optimizer, and loss function\n","model = initialize_model(num_classes)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# Move the model to the appropriate device\n","model.to(device)\n","\n","# Train the model\n","train_model(model, train_loader, loss_fn, optimizer, device, epochs=10)\n","\n","# Suppose you have a validation loader set up similarly\n","# evaluate_model(model, validation_loader, loss_fn, device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y80DkVyAlqn-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
